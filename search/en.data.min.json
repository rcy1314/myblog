[{"id":0,"href":"/myblog/categories/","title":"Categories","parent":"小惡魔 - AppleBOY","content":"","description":""},{"id":1,"href":"/myblog/categories/golang/","title":"Golang","parent":"Categories","content":"","description":""},{"id":2,"href":"/myblog/posts/","title":"Posts","parent":"小惡魔 - AppleBOY","content":"","description":""},{"id":3,"href":"/myblog/categories/system-design/","title":"System Design","parent":"Categories","content":"","description":""},{"id":4,"href":"/myblog/","title":"小惡魔 - AppleBOY","parent":"","content":"","description":""},{"id":5,"href":"/myblog/posts/create-server-and-worker-for-cancel-task-in-golang/","title":"用 Go 語言建立 Web 及 Worker 服務實現取消任務 (二)","parent":"Posts","content":"\n上一篇『系統設計: 如何取消正在執行的工作任務 (一)』教大家如何用 Go 語言實現 canceler package 來紀錄及取消正在執行的任務。而本篇來實現上圖的 HTTP Server 及 Worker 程式碼，底下直接用 Gin 框架來快速實現 HTTP 兩個 Handle，分別是 Cancel Task 及 Ｗatch Task (如下圖標示的 1 跟 2)。\n其中上圖綠色框框 1 是用來接收使用者想要取消的任務，而 2 是用來讓 worker 進行長連接，根據不同的情境可以設定不同的等待時間。大家可能會問，為什麼不讓 Server 主動通知 Worker 就可以了，先解釋這點，這邊我們可能要先假設 Worker 存在的環境是封閉的，不能任意架設服務，故需要主動向 HTTP Server 進行詢問。其中 HTTP Server 跟 Worker 中間可以透過 gRPC 或 RESTful 進行資料交換，本篇先以 RESTful 進行說明。\n實現 HTTP 服務 先透過 Gin 框架簡單實現 HTTP 服務\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() // listen and serve on 0.0.0.0:8080 (for windows \u0026#34;localhost:8080\u0026#34;) } 先來看看使用者取消任務 (ID 為 1234)，服務端該如何實現？上一篇教學有實現了 schedule package\npackage schedule type Engine struct { *canceler } func New() *Engine { return \u0026amp;Engine{ canceler: newCanceler(), } } 這時候只需要透過 New() 就可以。\n// initial schedule instance s := schedule.New() 接著實現 Cancel Task Handler。\nr.GET(\u0026#34;/cancel-task/:id\u0026#34;, func(c *gin.Context) { taskID := c.Param(\u0026#34;id\u0026#34;) if err := s.Cancel(context.Background(), taskID); err != nil { c.String(http.StatusInternalServerError, \u0026#34;crash\u0026#34;) return } c.String(http.StatusOK, \u0026#34;ok\u0026#34;) }) 上述函式執行 Cancel 會將任務 ID 直接紀錄在 struct map 內，後續可以接著更新任務狀態為『取消』，這邊就看大家怎麼存任務，最直接的方式就是更新資料庫。接著時線 Watch Task 函式\n要做到即時取消任務，故 Worker 需要長時間連接上 HTTP 服務，避免過多的請求，造成不必要的負擔，畢竟任務可能需要長時間去跑，時間設定太短，就會造成 HTTP Server 的負擔。\nr.GET(\u0026#34;/watch-task/:id\u0026#34;, func(c *gin.Context) { taskID := c.Param(\u0026#34;id\u0026#34;) ctxDone, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() ok, _ := s.Cancelled(ctxDone, taskID) if ok { c.String(http.StatusOK, \u0026#34;true\u0026#34;) return } c.String(http.StatusOK, \u0026#34;false\u0026#34;) }) 上述程式碼可以看到，透過宣告 context timeout 來決定需要等待多長的時間，超過時間後就回覆 false，由 HTTP 服務端決定 Worker 連接上來後可以等待的時間。\n實現 Worker 服務 簡單的 Worker 範例就是開幾個 Goroutine 去持續跟 HTTP 服務連線，直到收到 Cancel 事件。\n先假設有兩個任務分別是 1234 及 5678，當這兩個任務正在執行的時候，也順便開 goroutine 在背景跟 HTTP 服務連接，等到任務結束或收到 HTTP 端的中指請求，則結束各自的 Goroutine。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;sync\u0026#34; ) func cancelTask(id string) []byte { req, err := http.NewRequest(http.MethodGet, \u0026#34;http://localhost:8080/watch-task/\u0026#34;+id, nil) if err != nil { fmt.Printf(\u0026#34;client: could not create request: %s\\n\u0026#34;, err) os.Exit(1) } res, err := http.DefaultClient.Do(req) if err != nil { fmt.Printf(\u0026#34;client: error making http request: %s\\n\u0026#34;, err) os.Exit(1) } resBody, err := io.ReadAll(res.Body) if err != nil { fmt.Printf(\u0026#34;client: could not read response body: %s\\n\u0026#34;, err) os.Exit(1) } return resBody } func main() { wg := \u0026amp;sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() for { resp := string(cancelTask(\u0026#34;1234\u0026#34;)) fmt.Println(\u0026#34;task[1234]: cancel the task:\u0026#34;, resp) if resp == \u0026#34;true\u0026#34; { fmt.Println(\u0026#34;task[1234]: get cancel event and canceld the task\u0026#34;) return } } }() wg.Add(1) go func() { defer wg.Done() for { resp := string(cancelTask(\u0026#34;5678\u0026#34;)) fmt.Println(\u0026#34;task[5678]: cancel the task:\u0026#34;, resp) if resp == \u0026#34;true\u0026#34; { fmt.Println(\u0026#34;task[5678]: get cancel event and canceld the task\u0026#34;) return } } }() wg.Wait() } 上面程式碼範例請不要直接套用在專案內，因為有些狀況尚未寫進去，像是一般 HTTP Client 不會用預設的 http.DefaultClient，因為沒有設定 Timeout 會讓系統整個掛掉，另外 Goroutine 也沒有傳入 Context，會造成背景 Goroutine 都不會結束。這邊只是為了講解才這樣寫的。\n整合測試 主要測試的目的就是，當第一個 worker 正在處理 1234 任務時，不知道什麼原因，突然跟 HTTP Server 失去連線 (上圖步驟二)，此時如果步驟一收到使用者發送取消的請求，Worker 恢復連線後，要正確即時收到 Cancel 事件，才能完成取消任務。\n心得 處理長時間的任務，可能會遇到底下問題\n如何取得目前任務的狀態？ 如何設定任務超時機制？ 如何跨服務取消任務？ 當 Worker 失去連線或不正常關閉，該如何讓 Task 可以重新執行？ 當有多台 Server + 多台 Worker 時，該如何配送任務及取消任務？ 團隊除了需要解決此架構之外，也把上述的機制也實現在 AWS SageMaker 上，打造 AWS MLOps 平台。本篇程式碼可以在這邊找到。\n","description":"\n上一篇『系統設計: 如何取消正在執行的工作任務 (一)』教大家如何用 Go 語言實現 canceler package 來紀錄及取消正在執行的任務。而本篇來實現上圖的 HTTP Server 及 Worker 程式碼，底下直接用 Gin 框架來快速實現 HTTP 兩個 Handle，分別是 Cancel Task 及 Ｗatch Task (如下圖標示的 1 跟 2)。\n其中上圖綠色框框 1 是用來接收使用者想要取消的任務，而 2 是用來讓 worker 進行長連接，根據不同的情境可以設定不同的等待時間。大家可能會問，為什麼不讓 Server 主動通知 Worker 就可以了，先解釋這點，這邊我們可能要先假設 Worker 存在的環境是封閉的，不能任意架設服務，故需要主動向 HTTP Server 進行詢問。其中 HTTP Server 跟 Worker 中間可以透過 gRPC 或 RESTful 進行資料交換，本篇先以 RESTful 進行說明。\n"},{"id":6,"href":"/myblog/posts/system-design-how-to-cancel-a-running-task-in-golang/","title":"用 Go 語言實作如何取消正在執行的工作任務 (一)","parent":"Posts","content":"\n本篇來聊聊『如何取消正在執行的工作任務』，當系統內有需要處理比較久或較多資源的任務，肯定會將這些任務丟到其他機器再執行，執行過程如果需要取消，會經過如上圖幾個步驟。先假設中間的過程不透過 Message Queue 機制，而是兩個服務進行溝通透過 RESTful 或 gRPC 方式。\n教學影片 00:00 情境介紹 02:08 設計問題優缺點 03:44 單機版本實現方式 06:04 worker 連線請求 08:44 User 取消任務請求 12:24 worker 斷線跟如何處理? 13:26 解決方式 (設計 Timeout 機制) 15:52 清除 map 不必要資訊 17:47 實作後心得 其他線上課程請參考如下\nDocker 容器實戰 Go 語言課程 使用情境 可以看到步驟一是 worker 會先發請求到後端服務，詢問目前正在執行的任務是否取消，這邊可以用一個長連接持續 30 秒或 1 分鐘才斷線。步驟二是 User 從 Web UI 端按下取消的按鈕。步驟三是後端服務接受到取消任務的請求，就回覆 Worker 到請求執行取消任務。\n大家可以想看看此情境該如何設計流程，先不考慮多台後端服務的情境，也不考慮使用 Message Queue 的方式來實作。也許大家有想到一種方式，就是當使用者按下取消時 (到步驟三)，後端服務將此任務的狀態改成取消。而 Worker 每次來詢問狀態 (步驟一)，後端就再查詢一次就可以了 (步驟四)，這方式也沒有不對，只是即時性效果比較差，如果是每 30 秒輪詢一次，就有可能 30 秒後才能取消任務，輪詢時間設定很短，又會造成過多不必要的連線請求。除了這種方式外，還有沒有其他方式可以不需要查詢資料庫就可以即時讓 Worker 知道目前任務狀態。\n單機實作方式 用 Go 語言來處理後端跟 Worker 之間的資料交換機制。可以看下圖，先實作 canceller package，裡面有兩個不同的 Method，一個是 Cancel 用來處裡使用者取消哪一筆任務，另一個是 Cancelled 用來接受 Worker 的連線請求。\n這邊先考慮單個後端服務，為什麼先只考慮單個後端呢？原因就是底下的解法只適合在單一後端下才可以，多個後端會造成資料不同步問題。設計 canceller 結構可以用 map 方式來紀錄目前有多少 worker 請求，其中 map 內的 string 用來記錄任務唯一 ID 識別。\ntype canceler struct { sync.Mutex subsciber map[string]chan struct{} } func newCanceler() *canceler { return \u0026amp;canceler{ subsciber: make(subsciber map[string]chan struct{}), } } 接著看 worker 發送一個任務請求時，該如何實現監聽 Cancelled 機制。\nfunc (c *canceler) Cancelled(ctx context.Context, id string) (bool, error) { subsciber := make(chan struct{}) c.Lock() c.subsciber[id] = subsciber c.Unlock() defer func() { c.Lock() delete(c.subsciber, id) c.Unlock() }() select { case \u0026lt;-ctx.Done(): return false, nil case \u0026lt;-subsciber: return true, nil } } Cancelled 內帶有兩個參數，一個是 conetxt 另一個是任務 ID，其中 context 可以用來設計此連線多久後會自動回覆給 worker 沒有收到任何 Cancel 狀態，後者就是紀錄此任務 ID。\nsubsciber := make(chan struct{}) c.Lock() c.subsciber[id] = subsciber c.Unlock() 上面在 map 紀錄此任務 ID 及宣告 struct{} 通道。等到收到 cancel 或是 context 狀態，就結束函式，並把 map 內的紀錄取消。\ndefer func() { c.Lock() delete(c.subsciber, id) c.Unlock() }() select { case \u0026lt;-ctx.Done(): return false, nil case \u0026lt;-subsciber: return true, nil } 最後來實現 User 怎麼觸發 Cancel 機制，就是透過上面 map 內的 struct channel 來完成。\nfunc (c *canceler) Cancel(ctx context.Context, id string) error { c.Lock() defer c.Unlock() if sub, ok := c.subsciber[id]; ok { close(sub) } return nil } 用 for 迴圈來掃 c.subsciber 所有任務是否有比對成功，比對成功後，就將 subsciber channel 關閉，這樣在 Cancelled 內就會觸發 channel 通知。最後寫了兩個測試證明這方法是可以正常運作，第一個是透過 User 觸發取消任務\nfunc TestUserCancelTask(t *testing.T) { var canceled bool var err error engine := newCanceler() stop := make(chan struct{}) go func() { canceled, err = engine.Cancelled(context.Background(), \u0026#34;test123456\u0026#34;) stop \u0026lt;- struct{}{} }() time.Sleep(1 * time.Second) engine.Cancel(context.Background(), \u0026#34;test123456\u0026#34;) \u0026lt;-stop if !canceled { t.Fatal(\u0026#34;can\u0026#39;t cancel task\u0026#34;) } if err != nil { t.Fatal(\u0026#34;get error\u0026#34;) } } 另一個是使用 context 搭配 cancel event 來結束函式\nfunc TestContextCancelTask(t *testing.T) { var canceled bool var err error engine := newCanceler() stop := make(chan struct{}) ctx, cancel := context.WithCancel(context.Background()) go func() { canceled, err = engine.Cancelled(ctx, \u0026#34;test123456\u0026#34;) stop \u0026lt;- struct{}{} }() cancel() \u0026lt;-stop if canceled { t.Fatal(\u0026#34;detect cancel task\u0026#34;) } if err != nil { t.Fatal(\u0026#34;get error\u0026#34;) } } 遇到問題 服務之間溝通時，總是會遇到服務斷線的問題，假設全部 worker 都跟後端失去連線，這時候 User 觸發了取消任務，這時候上述代碼要如何調整才能讓 worker 恢復連線後又可以正常拿到取消任務的命令？\n其實很簡單，只需要一個簡單的 Timeout 機制，User 按下取消時，先以當下時間加上 5 分鐘，這 5 分鐘是什麼意思呢？也就是 worker 必須在這 5 分鐘內重新連上後端服務才可以正常拿到 cancel 事件，所以在 canceller 內加上 map 存取所有任務時間資訊。大家請注意這 5 分鐘數字，你可以根據自家系統流程而改變。\ntype canceler struct { sync.Mutex subsciber map[string]chan struct{} + cancelled map[string]time.Time } 接下來在 Cancel 函式內宣告時間\nfunc (c *canceler) Cancel(ctx context.Context, id string) error { c.Lock() defer c.Unlock() + c.cancelled[id] = time.Now().Add(5 * time.Minute) if sub, ok := c.subsciber[id]; ok { close(sub) } + c.clear() return nil } 最後請在 Cancelled 函式內補上底下判斷該任務是否存在\nfunc (c *canceler) Cancelled(ctx context.Context, id string) (bool, error) { subsciber := make(chan struct{}) c.Lock() c.subsciber[id] = subsciber c.Unlock() defer func() { c.Lock() delete(c.subsciber, id) c.Unlock() }() + c.Lock() + _, ok := c.cancelled[id] + c.Unlock() + if ok { + return true, nil + } select { case \u0026lt;-ctx.Done(): return false, nil case \u0026lt;-subsciber: return true, nil } } 除了解決上述問題外，也要想想怎麼定時清除 c.cancelled 多餘的資訊，避免任務要重新執行時，直接馬上收到 cancel event.\nfunc (c *canceler) clear() { now := time.Now() for k, trigger := range c.cancelled { if now.After(trigger) { delete(c.cancelled, k) } } } 最後補上測試，先執行 Cancel 代表 User 取消執行的任務，接著 Worker 發送請求詢問，由於我們有給 5 分鐘緩衝，所以時間內都可以拿到取消任務的指令。\nfunc TestUserCancelTaskFirst(t *testing.T) { var canceled bool var err error engine := newCanceler() // User cancel task first and _ = engine.Cancel(context.Background(), \u0026#34;test1234\u0026#34;) canceled, err = engine.Cancelled(context.Background(), \u0026#34;test1234\u0026#34;) if !canceled { t.Fatal(\u0026#34;can\u0026#39;t get cancel event\u0026#34;) } if err != nil { t.Fatal(\u0026#34;get error\u0026#34;) } } 心得 本篇最主要是要用 Go 語言的 Channel 特性來處理兩個服務之間的溝通機制，大家可能想到的解法就是用 Message Queue 來處理，但是有時候把架構想的更簡單一點，用 Go 語言的特性來處理，那就減少一個服務的維運，未來要將此架構轉換到其他平台就會更簡單，其他部門有需求會是將整套服務架設在不同團隊內，這時候架構越簡單，除錯時間會越短。最後附上程式碼，大家可以直接取用試試看。\n接下來會介紹關於如何實現 HTTP Server 跟 Worker 的代碼，有興趣可以繼續往下看『系統設計: 建立 Web 及 Worker 服務實現取消任務 (二)』。\n","description":"\n本篇來聊聊『如何取消正在執行的工作任務』，當系統內有需要處理比較久或較多資源的任務，肯定會將這些任務丟到其他機器再執行，執行過程如果需要取消，會經過如上圖幾個步驟。先假設中間的過程不透過 Message Queue 機制，而是兩個服務進行溝通透過 RESTful 或 gRPC 方式。\n"},{"id":7,"href":"/myblog/posts/simple-scheduler-with-multiple-worker-using-golang/","title":"系統設計: 處理服務讀取多個任務遇到的問題 (Go 語言)","parent":"Posts","content":"\n不同的服務都會有需要處理比較久的任務，這些任務是不能即時執行完成，才回應給前端，這樣使用者體驗會非常的差。將類型的任務存在資料庫或放在消息對列就是一種處理方式，接著啟動另一個服務來消化非即時性的任務，而常見的處理方式就是在服務內啟動多個 Worker Node 來平行消化任務 (如上圖)。\n教學影片 00:00 問題描述 02:52 如何用 Go 語言寫出多個 Worker 04:09 執行結果及問題展示 05:00 優化多個請求變成單一個 05:52 新增 Metric struct 用來記錄多少 Worker Node 執行中 06:41 設計 ready channel 判斷是否有新的 Worker Node 09:00 總結流程步驟 11:25 最終執行成果 其他線上課程請參考如下\nDocker 容器實戰 Go 語言課程 讀取多個任務問題 先看看底下此服務內部的設計，用 Go 語言來當範例解釋當下問題，假設 Task 服務負責存放所有的任務，而 Agent 服務內可以開啟多個 Goroutine 來平行消化任務，步驟也很簡單，第一步就去讀取任務，而第二步就是執行。在步驟一時，設計每 5 秒才向 Task 服務詢問是否有新任務需要執行，時間區隔避免頻繁發請求給 Task 服務。\n先假設有 100 個任務需要等待執行，在 Agent 內開啟 10 個 Worker Node 去消化，這樣每次就會發送 10 個請求，而這 10 個請求有可能對於 Task 服務來說就是 10 個 SQL 指令，如果是 10 台 Agent 就變成 100 個請求，這樣對於 Task 服務來說會負擔太大。\n大家可以想看看如何解決上述的問題，底下提供一段 Go 語言實作多個 Worker 的代碼，步驟一就是開啟 Goroutine 來平行處理任務，就是在這邊會發送大量的請求到另一個 Task 服務\ntype Poller struct { routineGroup *routineGroup workerNum int } func (p *Poller) Poll(ctx context.Context) error { for i := 0; i \u0026lt; p.workerNum; i++ { // step01 p.routineGroup.Run(func() { for { select { case \u0026lt;-ctx.Done(): return default: // step02 task, err := p.fetch(ctx) if err != nil { log.Println(\u0026#34;can\u0026#39;t get task\u0026#34;, err.Error()) break } // step03 if err := p.execute(ctx, task); err != nil { log.Println(\u0026#34;execute task error:\u0026#34;, err.Error()) } } } }) } p.routineGroup.Wait() return nil } 改善系統設計 為了解決不要發送大量的請求，我們可以在最前面多設計一個 Scheduler 來確保一次只讀取一個任務後，才繼續執行下一個讀取任務。大家可以看看底下的設計圖\n從上面的設計圖，我們需要在 Poller 的 struct 內紀錄目前有多少個 Worker Node 正在執行，故新增一個 Metric struct 來記錄這些資訊\ntype metric struct { busyWorkers uint64 } // newMetric for default metric structure func newMetric() *metric { return \u0026amp;metric{} } func (m *metric) IncBusyWorker() uint64 { return atomic.AddUint64(\u0026amp;m.busyWorkers, 1) } func (m *metric) DecBusyWorker() uint64 { return atomic.AddUint64(\u0026amp;m.busyWorkers, ^uint64(0)) } func (m *metric) BusyWorkers() uint64 { return atomic.LoadUint64(\u0026amp;m.busyWorkers) } 有了上述資訊後，接著在 Poller 內多新增一個 ready channel 用來判斷是否有新的 Worker 可以分配。所以在初始化的 for 迴圈內需要判斷是否有新的 Worker Node 可以執行。\nfunc (p *Poller) schedule() { p.Lock() defer p.Unlock() if int(p.metric.BusyWorkers()) \u0026gt;= p.workerNum { return } select { case p.ready \u0026lt;- struct{}{}: default: } } 接著改寫整體 Poll 函示，多寫一個 for 迴圈來判斷是否有新的 Worker Node\nfunc (p *Poller) Poll(ctx context.Context) error { // scheduler for { // step01 p.schedule() select { case \u0026lt;-p.ready: case \u0026lt;-ctx.Done(): return nil } LOOP: for { select { case \u0026lt;-ctx.Done(): break LOOP default: // step02 task, err := p.fetch(ctx) if err != nil { log.Println(\u0026#34;fetch task error:\u0026#34;, err.Error()) break } p.metric.IncBusyWorker() // step03 p.routineGroup.Run(func() { if err := p.execute(ctx, task); err != nil { log.Println(\u0026#34;execute task error:\u0026#34;, err.Error()) } }) break LOOP } } } } 可以看到流程步驟會變成底下\n判斷使否有新的 Worker Node 可以執行 單一 Worker Node 讀取是否有新任務 如果有新的任務，則紀錄 Worker Node + 1 返回步驟一 只要任何任務完成後，就將 Worker Node 數量再減一，並重新執行 p.schedule()，確保 ready channel 不為空。\nfunc (p *Poller) execute(ctx context.Context, task string) error { defer func() { p.metric.DecBusyWorker() p.schedule() }() return nil } 心得 上述測試的代碼可以直接參考這邊，也許大家有其他方式可以解決此問題，像是用 Message Queue 避免大量請求也是一種解決方案，只是如果能不起另一種服務是最好的，畢竟團隊內有時候需要將整套流程打包放到客戶端環境，多起一種服務，這樣要除錯又更不方便了。\n","description":"\n不同的服務都會有需要處理比較久的任務，這些任務是不能即時執行完成，才回應給前端，這樣使用者體驗會非常的差。將類型的任務存在資料庫或放在消息對列就是一種處理方式，接著啟動另一個服務來消化非即時性的任務，而常見的處理方式就是在服務內啟動多個 Worker Node 來平行消化任務 (如上圖)。\n"},{"id":8,"href":"/myblog/tags/diagrams/","title":"diagrams","parent":"Tags","content":"","description":""},{"id":9,"href":"/myblog/tags/draw.io/","title":"draw.io","parent":"Tags","content":"","description":""},{"id":10,"href":"/myblog/tags/excalidraw/","title":"excalidraw","parent":"Tags","content":"","description":""},{"id":11,"href":"/myblog/tags/plantuml/","title":"PlantUML","parent":"Tags","content":"","description":""},{"id":12,"href":"/myblog/tags/","title":"Tags","parent":"小惡魔 - AppleBOY","content":"","description":""},{"id":13,"href":"/myblog/tags/vscode/","title":"VSCode","parent":"Tags","content":"","description":""},{"id":14,"href":"/myblog/posts/three-tools-design-system-architecture-and-flow/","title":"三款好用的繪圖工具來解決系統架構或流程圖","parent":"Posts","content":"\n不管是長官還是同事甚至下屬，在公司無時無刻都需要跨團隊進行溝通，當系統架構或流程越來越複雜的時候，如果沒有按照當下情況記錄下來，對於未來接手的同事，或者是自己都會不小心忘記，而在記憶最清楚的當下用文字或流程圖記錄下來，對團隊及自己是有相當大的幫助。而有沒有工具可以快速畫出系統架構或流程圖？我們可以分幾種情境來討論。\n第一種是程式碼架構流程圖，跟開發團隊一起開發功能時，開發者可以先將程式的流程圖先畫出來，跟團隊進行第一輪討論，避免實作下去時，考慮太少，多與團隊進行溝通，對自己是非常有幫助的。\n第二種是專案剛開始，或發展到一定程度，需要將全部系統架構整理下來，團隊可能用了 AWS 或 GCP 等服務，有一個全貌的系統架構圖，可以協助團隊釐清專案到底使用了哪些工具？讓剛加入的同事可以透過此架構圖快速了解並進入狀況。底下來介紹三套我個人蠻推薦的三種繪製工具。\n教學影片 00:00 為什麼需要畫系統架構圖 00:49 第一種情境 01:28 第二種情境 02:07 第一套好用工具 PlantUML 05:50 第二套 Diagrams 07:40 第三套 Excalidraw 09:08 使用時機 其他線上課程請參考如下\nDocker 容器實戰 Go 語言課程 PlantUML PlantUML 是可以用純文本語言繪製圖表的開源軟體，由於是純文字語言，所以可以搭配版本控制做紀錄，非常適合團隊或跨團隊合作溝通，尤其是架構初期，會需要常常修改，所以用 PlantUML 非常適合，跟同事進行快速討論迭代修正。\n強大的 PlantUML 有提供線上版本進行撰寫，叫做 PlantText，除了線上版本讓大家可以測試之外，開發者也可以透過 VSCode 的 PlantUML 套件進行整合，一邊撰寫流程，一邊預覽，如下圖\n拿一個實際案例來看看\n@startuml Converter CLI queue \u0026#34;AWS SQS\u0026#34; as queue order 20 actor \u0026#34;User\u0026#34; as user order 10 database \u0026#34;AWS S3\u0026#34; as s3_storage order 15 participant \u0026#34;API Server\u0026#34; as api_server order 50 box \u0026#34;Docker Container\u0026#34; #LightBlue participant \u0026#34;Go Service\u0026#34; as go_cli order 30 #99FF99 participant \u0026#34;Python CLI\u0026#34; as python_cli order 40 #99FF99 database \u0026#34;Local Storage\u0026#34; as local_storage order 35 end box autonumber go_cli -\u0026gt; queue: Listen Notification Queue user -\u0026gt; s3_storage: Upload Dataset queue \u0026lt;- s3_storage: Send Notification go_cli \u0026lt;- queue: Receive Notification go_cli -\u0026gt; local_storage: Create /tmp folder go_cli \u0026lt;- s3_storage: Download Origin Dataset go_cli -\u0026gt; local_storage: Save Dataset to /tmp folder go_cli -\u0026gt; python_cli: Execute CLI command python_cli -[#0000FF]\u0026gt; local_storage: Save Progress Number to /tmp folder go_cli -\u0026gt; api_server: Upload Convert Progress python_cli -[#0000FF]\u0026gt; local_storage: Save output.zip and dataset.yml to /tmp go_cli -\u0026gt; api_server: Upload dataset type and class number go_cli -\u0026gt; s3_storage: Upload output.zip to S3 go_cli -\u0026gt; api_server: Upload Status to Success go_cli -\u0026gt; queue: Remove Notification @enduml 產生的圖如下，或線上編輯測試看看\n從上圖就可以知道透過 CLI 工具上傳 Dataset 到 AWS S3 會經過哪些步驟跟流程。假設沒有先把流程圖畫出來，其實很難想像跨團隊要怎麼合作。\nDiagrams 上面的 PlantUML 協助團隊釐清開發流程圖，假設您需要更多工具或圖形介面來描述整體的系統架構圖，也或者是需要對上對下報告有一個更完整的全貌，推薦大家使用 Diagrams，裡面有完整的圖庫跟功能，也支援離線桌面版或線上修改。可以把檔案放在 GitHub 內由線上版讀取。來看看底下可以教學影片體驗 Diagrams 的強大\n繪製完成後，可以輸出任何檔案格式。底下看看一張系統架構圖\nExcalidraw 除了上述兩套工具外，如果你想要快速畫出一個流程圖，又不想裝一大堆工具，強烈推薦 Excalidraw 這套線上流程圖軟體，它也是開源軟體。底下看看實際案例，我放在 redisdb-stream 專案內的架構圖。\n另外可以參考 Signoz 公開的文件：Logs Overview，裡面大量用到 Excalidraw 畫出來的流程圖。\n心得結論 上面有三套好用的畫圖工具，我個人使用的時機不盡相同，如果是簡易的流程圖，我都直接用 Excalidraw 快速搞定，不想花太多時間進行繪製，尤其是時間很趕的時候。跨團隊或內部開發溝通時，我就會用 PlantUML，將開發流程描述清楚，避免在合作上面出現差錯，讓其他開發同仁產生誤會。到專案中期或後期，整體架構比較確定後，我會在用 Diagrams 繪製系統流程，讓團隊或長官可以更加了解專案的全貌。\n","description":"\n不管是長官還是同事甚至下屬，在公司無時無刻都需要跨團隊進行溝通，當系統架構或流程越來越複雜的時候，如果沒有按照當下情況記錄下來，對於未來接手的同事，或者是自己都會不小心忘記，而在記憶最清楚的當下用文字或流程圖記錄下來，對團隊及自己是有相當大的幫助。而有沒有工具可以快速畫出系統架構或流程圖？我們可以分幾種情境來討論。\n"},{"id":15,"href":"/myblog/tags/dependency-injection/","title":"dependency injection","parent":"Tags","content":"","description":""},{"id":16,"href":"/myblog/tags/golang/","title":"golang","parent":"Tags","content":"","description":""},{"id":17,"href":"/myblog/posts/dependency-injection-in-go/","title":"用 Google 團隊推出的 Wire 工具解決 Dependency Injection","parent":"Posts","content":"\n不知道大家在用 Go 語言寫服務的時候，會不會遇到 Components 會有相互依賴的關係，A 物件依賴 B 物件，B 物件又依賴 C 物件，所以在初始化 A 物件前，就必須先將 B 跟 C 初始化完成，這就是錯綜復雜的關係。也許大家會想到另一個做法，就是把每個物件都宣告成全域變數，我個人不推薦這個使用方式，雖然很方便，但是就會讓整體架構變得很複雜。而本篇要介紹一個救星工具，就是 Google 團隊開發的 Wire 工具，官方部落格也可以參考看看。此工具就是為了解決底下兩個問題 (dependency injection)。\nComponents 互相依賴錯綜復雜的關係 不要宣告全域變數 教學影片 00:00 Dependency Injection 是什麼 00:23 模組相依性產生的問題 02:09 用程式碼講解問題出在哪邊 05:29 撰寫 wire.go 代碼，宣告 application struct 06:52 撰寫 inject_router.go 07:49 撰寫 inject_user.go 09:06 產生 wire_gen.go 代碼 10:36 安裝 wire 工具 11:17 wire_gen.go 內容是什麼 12:23 如何簡化 main.go 內容 14:04 如何再次修改 dependency 其他線上課程請參考如下\nDocker 容器實戰 Go 語言課程 模組依賴問題 底下所有程式碼都可以在這邊找到。\n大家參考上面這張圖，開發者想要在 main.go 內宣告 User 的 struct，就會需要一層一層依賴，所以代碼會寫成如下\ncfg, err := config.Environ() if err != nil { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } c, err := cache.New(cfg) if err != nil { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } l, err := ldap.New(cfg, c) if err != nil { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } cd, err := crowd.New(cfg, c) if err != nil { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } u, err := user.New(l, cd, c) if err != nil { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } if ok := u.Login(\u0026#34;test\u0026#34;, \u0026#34;test\u0026#34;); !ok { log.Fatal(). Err(err). Msg(\u0026#34;invalid configuration\u0026#34;) } m := graceful.NewManager() srv := \u0026amp;http.Server{ Addr: cfg.Server.Port, Handler: router.New(cfg, u), ReadHeaderTimeout: 5 * time.Second, ReadTimeout: 5 * time.Minute, WriteTimeout: 5 * time.Minute, MaxHeaderBytes: 8 * 1024, // 8KiB } 上述代碼大家可以想一下，如果是幾 10 個 Components 寫起來就會更加複雜。其實我們在主程式內只有用到 user 跟 router 而已，光是宣告其他 component 就寫了一堆代碼，我們是否可以將代碼優化成一個 struct\ntype application struct { router http.Handler user *user.Service } func newApplication( router http.Handler, user *user.Service, ) *application { return \u0026amp;application{ router: router, user: user, } } 這樣只要宣告 application 中間的 dependency 都透過 wire 幫忙處理。\n使用 Wire 工具 func newApplication( router http.Handler, user *user.Service, ) *application { return \u0026amp;application{ router: router, user: user, } } 要讓 wire 工具可以知道上面全部的依賴關係，先建立一個初始化函式，注意 wireinject 這個 build 標籤是不能拿掉的，這是給 wire CLI 工具辨認用的。\n//go:build wireinject // +build wireinject package main import ( \u0026#34;github.com/go-training/example49-dependency-injection/config\u0026#34; \u0026#34;github.com/google/wire\u0026#34; ) func InitializeApplication(cfg config.Config) (*application, error) { wire.Build( routerSet, userSet, newApplication, ) return \u0026amp;application{}, nil } 大家可以看到我們需要告知 wire 工具，router, user 及 newApplication 的關係，所以在分別建立 inject_router.go 跟 inject_user.go 兩個檔案，先看看 router 部分\nvar routerSet = wire.NewSet( //nolint:deadcode,unused,varcheck provideRouter, ) func provideRouter( cfg config.Config, user *user.Service, ) http.Handler { return router.New(cfg, user) } 這邊只有依賴 config 跟 user 兩物件並回傳 http.Handler，接下來 user 部分\nvar userSet = wire.NewSet( //nolint:deadcode,unused,varcheck provideUser, provideLDAP, provideCROWD, provideCache, ) func provideUser( l *ldap.Service, c *crowd.Service, cache *cache.Service, ) (*user.Service, error) { return user.New(l, c, cache) } func provideLDAP( cfg config.Config, cache *cache.Service, ) (*ldap.Service, error) { return ldap.New(cfg, cache) } func provideCROWD( cfg config.Config, cache *cache.Service, ) (*crowd.Service, error) { return crowd.New(cfg, cache) } func provideCache( cfg config.Config, ) (*cache.Service, error) { return cache.New(cfg) } user 依賴了 cache, ldap 跟 crowd 三個物件，完成後就可以透過 wire 指令產生 wire_gen.go 檔案\nwire gen ./... 打開 wire_gen.go\nfunc InitializeApplication(cfg config.Config) (*application, error) { service, err := provideCache(cfg) if err != nil { return nil, err } ldapService, err := provideLDAP(cfg, service) if err != nil { return nil, err } crowdService, err := provideCROWD(cfg, service) if err != nil { return nil, err } userService, err := provideUser(ldapService, crowdService, service) if err != nil { return nil, err } handler := provideRouter(cfg, userService) mainApplication := newApplication(handler, userService) return mainApplication, nil } 可以看到透過我們自己定義的 provide 前綴的函式，wire 工具自動幫我們把相依信都處理完畢，所以這工具讓你在主程式內把所以相依性都處理完畢，不要再使用全域變數了。\n心得 除了使用在 main 函式，還可以用在測試上面，測試也是要把依賴性都處理完畢，這樣才方便測試。相信大家處理依賴性肯定會遇到這問題。好的做法就是不要在 package 內宣告其他 package 的設定，這樣會非常難維護，畢竟一開始把所有的物件都初始化完畢，除錯的時候會相對容易。程式碼可以這邊觀看。\n","description":"\n不知道大家在用 Go 語言寫服務的時候，會不會遇到 Components 會有相互依賴的關係，A 物件依賴 B 物件，B 物件又依賴 C 物件，所以在初始化 A 物件前，就必須先將 B 跟 C 初始化完成，這就是錯綜復雜的關係。也許大家會想到另一個做法，就是把每個物件都宣告成全域變數，我個人不推薦這個使用方式，雖然很方便，但是就會讓整體架構變得很複雜。而本篇要介紹一個救星工具，就是 Google 團隊開發的 Wire 工具，官方部落格也可以參考看看。此工具就是為了解決底下兩個問題 (dependency injection)。\nComponents 互相依賴錯綜復雜的關係 不要宣告全域變數 "},{"id":18,"href":"/myblog/about/","title":"關於我","parent":"小惡魔 - AppleBOY","content":" Personal Picture： Personal Information： Name：Bo-Yi Wu (吳柏毅) Nick：appleboy Birth Date：Feb. 25th, 1983 Email：appleboy.tw AT gmail.com Education： M.S National Chung Cheng University Electric engineering ( 2007.09 ~ 2009.01) B.S National Dong Hwa University Electric engineering ( 2001.09 ~ 2005.06 ) 高雄市道明中學 ( 1999.09 ~ 2001.06 ) 高雄市正義高中 ( 1998.09 ~ 1999.06 ) 高雄市英明國中 ( 1995.09 ~ 1998.06 ) 高雄市四維國小 ( 1989.09 ~ 1995.06 ) Specialty： Programming languages Perl, Shell Program, C#, Java, C/C++, Python, Golang Web development Frontend: CSS3, HTML5, Bootstrap/Material Design, RWD, ES2015 / ES2016, jQuery, ReactJS, BackboneJS Webpack / RequireJS / GruntJS / Yeoman / GulpJS LESS / SASS / CSSNext / PostCSS Backend: PHP, ASP.NET, Node.js, Python, Golang Database: MySQL, Postgresql, MSSQL, Percona XtraDB Cluster MVC: CodeIgniter, Laravel, Express, SailsJS System administration FreeBSD, Linux(Ubuntu,Fedora,CentOS), Amazon Web Services Interests： Computer Science \u0026amp; Programming Weight Training Mountain-climbing Movie Project： 程式相關作品集可以參考 Github 連結\nCodeIgniter 繁體中文官方網站 [開發\u0026amp;維護] PHP-CodeIgniter-Framework-Taiwan 繁體中文翻譯計畫 A Plurk API Implementation with PHP CodeIgniter Plurk API CodeIgniter Google URL Shortener API CodeIgniter Template Library FreeBSD ports committer, maintainer of several FreeBSD Ports Presentation： 2016.04.21 Docker 基礎介紹與實戰 2016.03.03 Why to choose laravel framework 2016.01.22 How to choose web framework 2015.04.10 Git Flow and JavaScript Coding Style 教育訓練 2014.09.26 You must know about CodeIgniter Popular Library 成大電算中心 2014.07.18 Automating your workflow with Gulp.js COSCUP 國際研討會 2014.04.12 Introduction to Percona XtraDB Cluster and HAProxy OSDC 國際研討會 2013.05.25 高雄 KSDG 分享: 打造團隊共同開發環境 2013.05.19 2013 Javascript Conference: 你不可不知的前端開發工具 2012.11.03 2012 PHPConf RESTful API Design \u0026amp; Implementation with CodeIgniter 2012.08.20 快速修正專案 PHP Coding Standards 2012.02.18 Codeignite 進階應用 (公司教育訓練) 2012.02.11 CodeIgniter 2.1.x 基礎介紹 (公司教育訓練) 2012.02.05 Git 版本控制介紹 (公司教育訓練) 2011.11.12 2011 PHPConf Introduction to CodeIgniter PHP Framework 2011.05.12 How to write Platform Devices and Drivers with FPGA via GPMC 2011.05.12 Introduction to Android G Sensor I²C Driver on Android 2011.04.16 CodeIgniter 2.0.X 版本介紹 (MVC 架構撰寫推廣) 2010.09.19 ICOS 2010『Introduction to CodeIgniter PHP MVC Framework』 2009.10.17 [講義]屏科大 PHP \u0026amp; MySQL 基礎教學投影片 2009.07.18 [CodeIgniter] Open Source PHP Web Framework 系列講座 2008.12.13 利用合作式通訊提昇搜尋使用者的成功率 2008.08.27 國立中正大學通訊網路組Linux教學 2007.12.21 南投國史館台灣文獻館數位典藏專案教育訓練 Experience： 2015 Taiwan PHP Conference 網站開發人員 2014 Taiwan PHP Conference 網站開發人員 Taiwan CodeIgniter PHP Framework 官網站長 Taiwan Laravel PHP Framework 官網站長 Information Contemplation Club MIS ( 2003.02 ~ 2005.06) MIS Dept. of EE in NDHU( 2003.02 ~ 2005.06) BBS, Mail, DNS, WWW Information Media Center MIS (2003.02 ~ 2005.06) MIS Dept. of EE in CCU( 2005.02 ~ 2006.03) Alumni.ee Mail 福利創意工作室 (2005.07 ~ 2006.04) 工作室創辦人 (人員：5~10人) 程式規劃、專案負責、業務接洽、系統建置 國史館-台灣文獻館MIS ( 2006.03 ~ 2007.05) 國家數位典藏計畫程式負責 文獻館整理組數位典藏程式開發 CCU Computer CenterMIS ( 2007.09 ~ 2009.01) 中正大學學生事務處 [程式維護] CN Journal 網路組組刊系統 [Xoops 程式開發] 中信鯨職業棒球隊 [系統維護開發] 中正大學 化學系伺服器管理 [系統維護開發] 中正大學::電機通訊網路組 FreeRadius 伺服器 [系統維護開發] 國立中正大學::第十屆全國實證經濟學論文研討會[系統維護開發] 中正大學學校首頁 [系統維護開發] 國立中正大學研發處::研究計畫專區 [系統維護開發] 高雄縣林園鄉公所網站 無障礙A+ [系統開發] 國立中正大學::犯罪研究中心 [系統開發 MVC CodeIgniter] 研究發展處技術推廣中心 [系統開發 MVC CodeIgniter] 國立中正大學::犯罪防治學系暨研究所 [系統開發 MVC CodeIgniter] 國立中正大學::文學院 [系統開發 MVC CodeIgniter] MozTw.org System Administrator MIS (2009.11 ~ Now) ","description":"Personal Picture： Personal Information： Name：Bo-Yi Wu (吳柏毅) Nick：appleboy Birth Date：Feb. 25th, 1983 Email：appleboy.tw AT gmail.com Education： M.S National Chung Cheng University Electric engineering ( 2007.09 ~ 2009.01) B.S National Dong Hwa University Electric engineering ( 2001.09 ~ 2005.06 ) 高雄市道明中學 ( 1999.09 ~ 2001.06 ) 高雄市正義高中 ( 1998.09 ~ 1999.06 ) 高雄市英明國中 ( 1995.09 ~ 1998.06 ) 高雄市四維國小 ( 1989.09 ~ 1995.06 ) Specialty： Programming languages Perl, Shell Program, C#, Java, C/C++, Python, Golang Web development Frontend: CSS3, HTML5, Bootstrap/Material Design, RWD, ES2015 / ES2016, jQuery, ReactJS, BackboneJS Webpack / RequireJS / GruntJS / Yeoman / GulpJS LESS / SASS / CSSNext / PostCSS Backend: PHP, ASP."},{"id":19,"href":"/myblog/archives/","title":"歷年文章","parent":"Posts","content":"","description":"歷年文章"}]